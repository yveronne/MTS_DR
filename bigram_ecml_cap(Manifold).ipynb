{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1229,
     "status": "ok",
     "timestamp": 1594296127488,
     "user": {
      "displayName": "Véronne Yepmo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgqH82zY4SlxjzAyvHbBobvn-Nfd4c_b3i6F_ADfA=s64",
      "userId": "01798836279637929908"
     },
     "user_tz": -120
    },
    "id": "HC0DNTF0BLqx"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from timeit import default_timer as timer\n",
    "import scipy.io as sio\n",
    "from scipy.special import comb\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from scipy.stats import expon\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.manifold import spectral_embedding\n",
    "import math\n",
    "\n",
    "\n",
    "import ensemble_learning as el"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P0wo7phzBLq9"
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 441,
     "status": "ok",
     "timestamp": 1594296131166,
     "user": {
      "displayName": "Véronne Yepmo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgqH82zY4SlxjzAyvHbBobvn-Nfd4c_b3i6F_ADfA=s64",
      "userId": "01798836279637929908"
     },
     "user_tz": -120
    },
    "id": "UldG0q3SBLq-"
   },
   "outputs": [],
   "source": [
    "def onegramsTransform(data,dim1,dim2,minb=2,maxbh=30,cv = 5):\n",
    "    #Removing missing values and store the result in the same variable\n",
    "    data.dropna(inplace=True)\n",
    "    #Grouping data by series\n",
    "    group = data.groupby('Series')\n",
    "    #Getting the different classes\n",
    "    classe = group['classe'].apply(lambda x : x.iloc[0]).reset_index(drop=True)\n",
    "    #Providing train/test indices to split data in train/test sets. Split dataset into cv consecutive folds, and shuffling the data before it\n",
    "    kf = KFold(n_splits=cv,shuffle=True)\n",
    "    mscore = 0\n",
    "    #b1 from 2 to 29...by default\n",
    "    for b1 in range(minb,maxbh):\n",
    "        hist = group.apply(lambda x : np.ndarray.tolist(np.ndarray.flatten(\n",
    "                    np.histogram(x.iloc[:,dim1].values,bins=b1,density=True)[0])))\n",
    "        hist_tr = pd.DataFrame(hist.values.tolist())\n",
    "\n",
    "        clf= KNeighborsClassifier(1)\n",
    "        clf.fit(hist_tr, classe)\n",
    "\n",
    "        scores = cross_val_score(clf, hist_tr, classe, cv=kf)\n",
    "\n",
    "        if mscore < np.median(scores):\n",
    "            \n",
    "            mscore = np.median(scores)\n",
    "            ubh1=b1\n",
    "            \n",
    "    #print(\"Bins: \", [ubh1], \" \\nMean scores : \", mscore)       \n",
    "            \n",
    "    mscore=0\n",
    "    for b1 in range(minb,maxbh):\n",
    "        hist = group.apply(lambda x : np.ndarray.tolist(np.ndarray.flatten(\n",
    "                    np.histogram(x.iloc[:,dim2].values,bins=b1,density=True)[0])))\n",
    "        hist_tr = pd.DataFrame(hist.values.tolist())\n",
    "\n",
    "        clf=KNeighborsClassifier(1)\n",
    "        clf.fit(hist_tr, classe)\n",
    "\n",
    "        scores = cross_val_score(clf, hist_tr, classe, cv=kf)\n",
    "\n",
    "        if mscore < np.median(scores):\n",
    "            \n",
    "            mscore = np.median(scores)\n",
    "            ubh2=b1\n",
    "\n",
    "    #print(\"Bins: \", [ubh2], \" \\nMean scores : \", mscore)\n",
    "\n",
    "    return ubh1,ubh2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 588,
     "status": "ok",
     "timestamp": 1594296134091,
     "user": {
      "displayName": "Véronne Yepmo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgqH82zY4SlxjzAyvHbBobvn-Nfd4c_b3i6F_ADfA=s64",
      "userId": "01798836279637929908"
     },
     "user_tz": -120
    },
    "id": "VR8WMCp6BLrC"
   },
   "outputs": [],
   "source": [
    "def bigramsTransform(data,dim1,dim2,minb=2,maxb=11,cv = 5):\n",
    "    data.dropna(inplace=True)\n",
    "    group = data.groupby('Series')\n",
    "    classe = group['classe'].apply(lambda x : x.iloc[0]).reset_index(drop=True)\n",
    "    kf = KFold(n_splits=cv,shuffle=True)\n",
    "    mscore = 0\n",
    "    for b1 in range(minb,maxb):\n",
    "        for b2 in range(minb,maxb):\n",
    "            hist = group.apply(lambda x : np.ndarray.tolist(np.ndarray.flatten(\n",
    "                        np.histogram2d(x.iloc[:,dim1].values,x.iloc[:,dim2].values,bins=[b1,b2],density=True)[0])))\n",
    "            hist_tr = pd.DataFrame(hist.values.tolist())\n",
    "\n",
    "            clf= KNeighborsClassifier(1)\n",
    "            clf.fit(hist_tr, classe)\n",
    "\n",
    "            scores = cross_val_score(clf, hist_tr, classe, cv=kf)\n",
    "\n",
    "            if mscore < np.median(scores):\n",
    "                \n",
    "                mscore = np.median(scores)\n",
    "                ub1=b1\n",
    "                ub2=b2\n",
    "    #print(\"Bins: \", [ub1,ub2], \" \\nMean scores : \", mscore) \n",
    "    return ub1,ub2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AZMg3K6NBLrH"
   },
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VIxwmaZwBLrI"
   },
   "source": [
    "### Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 454,
     "status": "ok",
     "timestamp": 1594296137303,
     "user": {
      "displayName": "Véronne Yepmo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgqH82zY4SlxjzAyvHbBobvn-Nfd4c_b3i6F_ADfA=s64",
      "userId": "01798836279637929908"
     },
     "user_tz": -120
    },
    "id": "NKXt8C2fBLrJ"
   },
   "outputs": [],
   "source": [
    "dataset = [[\"ArabicDigits/ArabicDigits\",\" \"],#0\n",
    "           [\"AUSLAN/AUSLAN\",\" \",\"\\t\"],#1\n",
    "           [\"CharacterTrajectories/CharacterTrajectories\",\"\\t\"], #2          \n",
    "           [\"CMUsubject16/CMUsubject16\",\"\\t\"],#3\n",
    "           [\"ECG/ECG\",\" \"],#4\n",
    "           [\"Libras/Libras\",\" \"],#5\n",
    "           [\"PenDigits/PenDigits\",\"\\t\"],#6\n",
    "           ['UWave/uWave',\" \"],#7\n",
    "           ['RobotFailure/LP1',\" \"],#8\n",
    "           ['RobotFailure/LP2',\" \"],#9\n",
    "           ['RobotFailure/LP3',\" \"],#10\n",
    "           ['RobotFailure/LP4',\" \"],#11\n",
    "           ['RobotFailure/LP5',\" \"],#12\n",
    "           ['Wafer/Wafer',\" \"],#13\n",
    "           [\"JapaneseVowels/JapaneseVowels\", \" \"], #14\n",
    "           [\"ArticularyWordRecognition/ArticularyWordRecognition\", \" \"],#15\n",
    "           [\"BasicMotions/BasicMotions\", \" \"], #16\n",
    "           [\"Cricket/Cricket\", \" \"], #17\n",
    "           [\"DuckDuckGeese/DuckDuckGeese\", \" \"], #18\n",
    "           [\"EigenWorms/EigenWorms\", \" \"], #19\n",
    "           [\"FingerMovements/FingerMovements\", \" \"], #20\n",
    "           [\"HandMovementDirection/HandMovementDirection\", \" \"], #21\n",
    "           [\"Heartbeat/Heartbeat\", \" \"], #22\n",
    "           [\"LSST/LSST\", \" \"], #23\n",
    "           [\"MotorImagery/MotorImagery\", \" \"], #24\n",
    "           [\"NATOPS/NATOPS\", \" \"], #25\n",
    "           [\"RacketSports/RacketSports\", \" \"], #26\n",
    "           [\"SelfRegulationSCP1/SelfRegulationSCP1\", \" \"], #27\n",
    "           [\"SelfRegulationSCP2/SelfRegulationSCP2\", \" \"] #28\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 554,
     "status": "ok",
     "timestamp": 1594298911437,
     "user": {
      "displayName": "Véronne Yepmo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgqH82zY4SlxjzAyvHbBobvn-Nfd4c_b3i6F_ADfA=s64",
      "userId": "01798836279637929908"
     },
     "user_tz": -120
    },
    "id": "QDyiM_6dBLrM",
    "outputId": "3634cecf-0406-4efb-ee11-a2c077b762ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         3         4         5         6         7         8         9  \\\n",
      "0  6.59375  13.00000  11.93750  16.40625  18.87500  18.90625  17.12500   \n",
      "1  6.59375  12.71875  12.43750  16.50000  19.56250  18.34375  17.03125   \n",
      "2  6.18750  12.84375  12.96875  16.06250  20.31250  17.75000  16.87500   \n",
      "3  6.03125  13.21875  13.12500  16.31250  20.84375  17.06250  16.50000   \n",
      "4  5.50000  13.31250  12.06250  16.46875  21.75000  16.56250  16.12500   \n",
      "\n",
      "         10        11       12  ...       59       60       61        62  \\\n",
      "0  13.90625  10.15625  2.06250  ... -0.12500 -10.4375 -8.12500 -11.37500   \n",
      "1  14.78125  10.03125  1.31250  ...  0.00000 -10.1250 -7.28125 -11.03125   \n",
      "2  14.62500  10.18750  1.18750  ... -0.53125  -9.9375 -6.53125 -10.87500   \n",
      "3  14.21875  10.18750  0.78125  ... -1.90625  -9.8125 -5.90625 -10.81250   \n",
      "4  14.03125   9.84375  0.40625  ... -2.56250  -9.8750 -5.62500 -10.68750   \n",
      "\n",
      "        63        64       65       66  classe  Series  \n",
      "0 -6.31250 -10.12500 -6.46875 -7.68750       1       1  \n",
      "1 -7.12500  -9.00000 -5.96875 -8.18750       1       1  \n",
      "2 -7.15625  -8.81250 -5.90625 -8.59375       1       1  \n",
      "3 -7.25000  -8.96875 -5.12500 -9.34375       1       1  \n",
      "4 -7.46875  -8.84375 -4.46875 -9.68750       1       1  \n",
      "\n",
      "[5 rows x 66 columns]\n"
     ]
    }
   ],
   "source": [
    "i=24\n",
    "\n",
    "train = pd.read_table(\"MTS_Datasets/\"+dataset[i][0]+\"_TRAIN\",sep=dataset[i][1],header=None)\n",
    "\n",
    "\n",
    "# Renommage des 3 premières colonnes représentant resp. les numéros des STM,\n",
    "# les indices de leurs obs et leur classe\n",
    "train.rename(index=str, columns={0: \"Series\", 1: \"index\", 2:\"classe\"},inplace=True)\n",
    "# Suppression de la colonne des index des obs des STM, infos inutiles pour les futures traitements\n",
    "# (d'où l'utilisation de inplace=True) sinon le dataframe appelant la méthode drop serait inchangé et \n",
    "# une copie modifiée serait retournée en résultat\n",
    "train.drop(['index'],axis=1,inplace=True) \n",
    "# Suppression et sauvegarde de la colonne des classes et celle des séries\n",
    "cl = train.pop('classe') \n",
    "se = train.pop('Series')\n",
    "# Insertion des colonnes précédemment supprimées à la fin du dataframe\n",
    "train['classe'] = cl\n",
    "train['Series'] = se\n",
    "# Convertion du type des colonnes en string\n",
    "train.columns = train.columns.astype(str)\n",
    "print(train.head())\n",
    "\n",
    "\n",
    "test = pd.read_table(\"MTS_Datasets/\"+dataset[i][0]+\"_TEST\",sep=dataset[i][1],header=None)\n",
    "test.rename(index=str, columns={0: \"Series\", 1: \"index\", 2:\"classe\"},inplace=True)\n",
    "test.drop(['index'],axis=1,inplace=True)\n",
    "cl = test.pop('classe')\n",
    "se = test.pop('Series')\n",
    "test['classe'] = cl\n",
    "test['Series'] = se\n",
    "test.columns = test.columns.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "heading_collapsed": true,
    "id": "8HgXCZpPBLrY"
   },
   "source": [
    "### Matlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9469,
     "status": "error",
     "timestamp": 1593453947197,
     "user": {
      "displayName": "Véronne Yepmo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgqH82zY4SlxjzAyvHbBobvn-Nfd4c_b3i6F_ADfA=s64",
      "userId": "01798836279637929908"
     },
     "user_tz": -120
    },
    "hidden": true,
    "id": "BzwRPnTZBLrZ",
    "outputId": "187866ce-5f98-497e-8cfa-d0f660d575a0"
   },
   "outputs": [],
   "source": [
    "mat = sio.loadmat('MTS_Datasets/PEMS/PEMS.mat')\n",
    "mdata = mat['mts']\n",
    "mdtype = mdata.dtype  \n",
    "ndata = {n: mdata[n][0, 0] for n in mdtype.names}\n",
    "columns = [n for n, v in ndata.items()]\n",
    "\n",
    "c='train'\n",
    "train = pd.DataFrame()\n",
    "for i in range(0,len(ndata[c][0])):\n",
    "    series = pd.DataFrame(np.transpose(ndata[c][0][i]))\n",
    "    series['classe']=ndata['trainlabels'][0][i]\n",
    "    series['Series']=i\n",
    "    train = pd.concat([train,series])\n",
    "train.reset_index(drop=True,inplace=True)\n",
    "\n",
    "\n",
    "c='test'\n",
    "test = pd.DataFrame()\n",
    "for i in range(0,len(ndata[c][0])):\n",
    "    series = pd.DataFrame(np.transpose(ndata[c][0][i]))\n",
    "    series['classe']=ndata['testlabels'][0][i]\n",
    "    series['Series']=i\n",
    "    test = pd.concat([test,series])\n",
    "test.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RHyLm0aMBLrh"
   },
   "source": [
    "# Pre_treatments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 498,
     "status": "ok",
     "timestamp": 1594298916621,
     "user": {
      "displayName": "Véronne Yepmo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgqH82zY4SlxjzAyvHbBobvn-Nfd4c_b3i6F_ADfA=s64",
      "userId": "01798836279637929908"
     },
     "user_tz": -120
    },
    "id": "9u8ikRi7BLrh",
    "outputId": "6330622e-392b-4a39-9b3f-f323dc788fbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "         3         4         5         6         7         8         9  \\\n",
      "0  6.59375  13.00000  11.93750  16.40625  18.87500  18.90625  17.12500   \n",
      "1  6.59375  12.71875  12.43750  16.50000  19.56250  18.34375  17.03125   \n",
      "2  6.18750  12.84375  12.96875  16.06250  20.31250  17.75000  16.87500   \n",
      "3  6.03125  13.21875  13.12500  16.31250  20.84375  17.06250  16.50000   \n",
      "4  5.50000  13.31250  12.06250  16.46875  21.75000  16.56250  16.12500   \n",
      "\n",
      "         10        11       12  ...       59       60       61        62  \\\n",
      "0  13.90625  10.15625  2.06250  ... -0.12500 -10.4375 -8.12500 -11.37500   \n",
      "1  14.78125  10.03125  1.31250  ...  0.00000 -10.1250 -7.28125 -11.03125   \n",
      "2  14.62500  10.18750  1.18750  ... -0.53125  -9.9375 -6.53125 -10.87500   \n",
      "3  14.21875  10.18750  0.78125  ... -1.90625  -9.8125 -5.90625 -10.81250   \n",
      "4  14.03125   9.84375  0.40625  ... -2.56250  -9.8750 -5.62500 -10.68750   \n",
      "\n",
      "        63        64       65       66  classe  Series  \n",
      "0 -6.31250 -10.12500 -6.46875 -7.68750       1       1  \n",
      "1 -7.12500  -9.00000 -5.96875 -8.18750       1       1  \n",
      "2 -7.15625  -8.81250 -5.90625 -8.59375       1       1  \n",
      "3 -7.25000  -8.96875 -5.12500 -9.34375       1       1  \n",
      "4 -7.46875  -8.84375 -4.46875 -9.68750       1       1  \n",
      "\n",
      "[5 rows x 66 columns]\n"
     ]
    }
   ],
   "source": [
    "# Détermination du nbre d'instances ou observations composant (les dimensions des) les STM\n",
    "nb_col = len(train.drop(['classe','Series'],axis=1).columns)\n",
    "print(nb_col)\n",
    "print(train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XIUvmNiNBLrl"
   },
   "source": [
    "## Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1096,
     "status": "ok",
     "timestamp": 1594298920727,
     "user": {
      "displayName": "Véronne Yepmo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgqH82zY4SlxjzAyvHbBobvn-Nfd4c_b3i6F_ADfA=s64",
      "userId": "01798836279637929908"
     },
     "user_tz": -120
    },
    "id": "URyKRM4zBLrm",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.iloc[:,0:nb_col] = train.groupby('Series').transform(lambda x: (x - x.min()) / (x.max()-x.min())).iloc[:,0:nb_col]\n",
    "test.iloc[:,0:nb_col] = test.groupby('Series').transform(lambda x: (x - x.min()) / (x.max()-x.min())).iloc[:,0:nb_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               3         4         5         6         7         8         9  \\\n",
      "0       0.387556  0.642804  0.617712  0.730216  0.799322  1.000000  0.966193   \n",
      "1       0.387556  0.636162  0.629520  0.732374  0.814237  0.987887  0.964165   \n",
      "2       0.376000  0.639114  0.642066  0.722302  0.830508  0.975101  0.960784   \n",
      "3       0.371556  0.647970  0.645756  0.728058  0.842034  0.960296  0.952671   \n",
      "4       0.356444  0.650185  0.620664  0.731655  0.861695  0.949529  0.944557   \n",
      "...          ...       ...       ...       ...       ...       ...       ...   \n",
      "833995  0.569044  0.083141  0.052348  0.212163  0.181755  0.049067  0.057360   \n",
      "833996  0.549317  0.080062  0.056197  0.212854  0.197650  0.022115  0.043538   \n",
      "833997  0.547800  0.082371  0.056197  0.185902  0.199724  0.017277  0.048376   \n",
      "833998  0.552352  0.077752  0.051578  0.173462  0.203870  0.018659  0.046994   \n",
      "833999  0.564492  0.058507  0.043110  0.165169  0.185211  0.019350  0.061507   \n",
      "\n",
      "              10        11        12  ...        59        60        61  \\\n",
      "0       0.899593  0.884164  0.694282  ...  0.477103  0.125666  0.204473   \n",
      "1       0.918589  0.881232  0.676686  ...  0.481363  0.136315  0.233227   \n",
      "2       0.915197  0.884897  0.673754  ...  0.463259  0.142705  0.258786   \n",
      "3       0.906377  0.884897  0.664223  ...  0.416400  0.146965  0.280085   \n",
      "4       0.902307  0.876833  0.655425  ...  0.394036  0.144835  0.289670   \n",
      "...          ...       ...       ...  ...       ...       ...       ...   \n",
      "833995  0.085823  0.193261  0.062617  ...  0.887631  0.718239  0.878826   \n",
      "833996  0.107438  0.205976  0.085786  ...  0.910692  0.698952  0.869602   \n",
      "833997  0.125874  0.223776  0.096431  ...  0.920755  0.691405  0.855765   \n",
      "833998  0.141132  0.230769  0.102066  ...  0.918658  0.698532  0.841090   \n",
      "833999  0.159568  0.221233  0.113964  ...  0.911530  0.714046  0.835639   \n",
      "\n",
      "              62        63        64        65        66  classe  Series  \n",
      "0       0.093717  0.283039  0.123558  0.219934  0.187809       1       1  \n",
      "1       0.105431  0.255983  0.153213  0.233114  0.174629       1       1  \n",
      "2       0.110756  0.254943  0.158155  0.234761  0.163921       1       1  \n",
      "3       0.112886  0.251821  0.154036  0.255354  0.144152       1       1  \n",
      "4       0.117146  0.244537  0.157331  0.272652  0.135091       1       1  \n",
      "...          ...       ...       ...       ...       ...     ...     ...  \n",
      "833995  0.791614  0.698113  0.813417  0.657442  0.766457       1     278  \n",
      "833996  0.805451  0.695597  0.802096  0.644444  0.747170       1     278  \n",
      "833997  0.802935  0.693920  0.800000  0.623899  0.740881       1     278  \n",
      "833998  0.802516  0.695178  0.792034  0.589937  0.739203       1     278  \n",
      "833999  0.797904  0.684277  0.773166  0.568973  0.754298       1     278  \n",
      "\n",
      "[834000 rows x 66 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 442,
     "status": "ok",
     "timestamp": 1594298925825,
     "user": {
      "displayName": "Véronne Yepmo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgqH82zY4SlxjzAyvHbBobvn-Nfd4c_b3i6F_ADfA=s64",
      "userId": "01798836279637929908"
     },
     "user_tz": -120
    },
    "id": "JvkrzDFJBLrq"
   },
   "outputs": [],
   "source": [
    "mask  = train.isna().all()\n",
    "\n",
    "#Drop columns where all elements are missing and keep the dataframe with valid entries in the same variable\n",
    "train.dropna(axis=1,how='all',inplace=True)\n",
    "\n",
    "train.interpolate(inplace=True)\n",
    "train.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 552,
     "status": "ok",
     "timestamp": 1594298929613,
     "user": {
      "displayName": "Véronne Yepmo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgqH82zY4SlxjzAyvHbBobvn-Nfd4c_b3i6F_ADfA=s64",
      "userId": "01798836279637929908"
     },
     "user_tz": -120
    },
    "id": "U_iC7I4uBLru"
   },
   "outputs": [],
   "source": [
    "test = test[test.columns[~mask]]\n",
    "test.dropna(axis=1,how='all',inplace=True)\n",
    "test.interpolate(inplace=True)\n",
    "test.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8UqxTyFqikHX"
   },
   "source": [
    "# Manifold learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kL5P73v-pYuZ"
   },
   "outputs": [],
   "source": [
    "grouped_df = train.groupby(\"Series\")\n",
    "aaaaa = []\n",
    "for key, item in grouped_df:\n",
    "    #print(grouped_df.get_group(key).shape[0], \"\\n\\n\")\n",
    "    aaaaa.append(grouped_df.get_group(key).shape[0])\n",
    "\n",
    "aaaaa.sort()\n",
    "print(aaaaa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 251
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6356,
     "status": "ok",
     "timestamp": 1594296195064,
     "user": {
      "displayName": "Véronne Yepmo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgqH82zY4SlxjzAyvHbBobvn-Nfd4c_b3i6F_ADfA=s64",
      "userId": "01798836279637929908"
     },
     "user_tz": -120
    },
    "id": "E6qngCN5Ofq5",
    "outputId": "0c264d93-f085-49fd-9ddf-2546a94626de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tslearn in /home/veyepmotch/anaconda3/lib/python3.7/site-packages (0.4.1)\n",
      "Requirement already satisfied: scikit-learn in /home/veyepmotch/anaconda3/lib/python3.7/site-packages (from tslearn) (0.22.1)\n",
      "Requirement already satisfied: Cython in /home/veyepmotch/anaconda3/lib/python3.7/site-packages (from tslearn) (0.29.15)\n",
      "Requirement already satisfied: scipy in /home/veyepmotch/anaconda3/lib/python3.7/site-packages (from tslearn) (1.4.1)\n",
      "Requirement already satisfied: joblib in /home/veyepmotch/anaconda3/lib/python3.7/site-packages (from tslearn) (0.14.1)\n",
      "Requirement already satisfied: numpy in /home/veyepmotch/anaconda3/lib/python3.7/site-packages (from tslearn) (1.18.1)\n",
      "Requirement already satisfied: numba in /home/veyepmotch/anaconda3/lib/python3.7/site-packages (from tslearn) (0.48.0)\n",
      "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /home/veyepmotch/anaconda3/lib/python3.7/site-packages (from numba->tslearn) (0.31.0)\n",
      "Requirement already satisfied: setuptools in /home/veyepmotch/anaconda3/lib/python3.7/site-packages (from numba->tslearn) (45.2.0.post20200210)\n"
     ]
    }
   ],
   "source": [
    "!pip install tslearn\n",
    "from tslearn.metrics import dtw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1925,
     "status": "ok",
     "timestamp": 1594298961144,
     "user": {
      "displayName": "Véronne Yepmo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgqH82zY4SlxjzAyvHbBobvn-Nfd4c_b3i6F_ADfA=s64",
      "userId": "01798836279637929908"
     },
     "user_tz": -120
    },
    "id": "6U-EquDlioXf",
    "outputId": "6580a6c8-4270-4f70-88e0-727fe3a0eccf"
   },
   "outputs": [],
   "source": [
    "def reduce(data, nbcol, dim=3, repetition=False):\n",
    "  # data is a dataframe representing a serie of the dataset\n",
    "  size = data.shape[0]\n",
    "    \n",
    "  # If the number or data points if less or equal to the reduced dimension wished, drop the series\n",
    "  if dim >= size:\n",
    "    data.drop(data.index, inplace=True)\n",
    "    return data\n",
    "  #if size > 25:\n",
    "  #  repetition = True\n",
    "    \n",
    "  end = size - 1 # Last index of A\n",
    "  bend = end - 1\n",
    "    \n",
    "  R = np.zeros((size, size)) # Repetition neighbourhood matrix\n",
    "\n",
    "  A = np.diag(np.diag(rbf_kernel(data, gamma=1),1), 1)\n",
    "  A = (A + A.transpose())\n",
    "  \n",
    "\n",
    "  if repetition == True: # We compute simultaneously the adjacent temporal neighbourhood matrix and the repetition temporal neighbourhood matrix\n",
    "\n",
    "    endRepetition = end-10 # Last index of the data points while computing the repetition neighbourhoods\n",
    "    fragmentNumbers = endRepetition - 9 # Number of fragments\n",
    "    M = np.zeros((fragmentNumbers, fragmentNumbers)) # Similarity matrix of the fragments\n",
    "    fragments = list() # List containing the fragments. Each element of the list contains the coordinates (extracted dataframe) of the data points in the fragment\n",
    "    M_mod = np.zeros((fragmentNumbers, fragmentNumbers)) # Similarity matrix M after windowing\n",
    "\n",
    "   \n",
    "    for i in range(1,end):\n",
    "      if i >= 10 and i <= endRepetition:\n",
    "        fragments.append(data.iloc[i-10:i+11, :nbcol])\n",
    "\n",
    "    # Computing the M matrix\n",
    "    for i in range(0,fragmentNumbers):\n",
    "      for j in range(0,i):\n",
    "        M[i,j] = dtw(fragments[i], fragments[j])\n",
    "        M[j,i] = M[i,j]\n",
    "\n",
    "    # Performing temporal windowing of M\n",
    "    for i in range(0,fragmentNumbers):\n",
    "      for j in range(i+1, fragmentNumbers):\n",
    "        for b in range(0, 20):\n",
    "          if i-b > 0 and j-b >0:  #  ET LES AUTRES ?\n",
    "            M_mod[i,j] = M_mod[i,j] + M[i-b,j-b]\n",
    "        M_mod[i,j] = M_mod[i,j] / 20\n",
    "        M_mod[j,i] = M_mod[i,j]\n",
    "        \n",
    "      \n",
    "\n",
    "    \n",
    "    # Searching for similar fragments, extracting the similar fragments and building the matrix R\n",
    "    b = 0.75\n",
    "    Bool = (M_mod < M_mod.mean(axis=1) - b * M_mod.std(axis=1))\n",
    "    for i in range(0, fragmentNumbers):\n",
    "      for j in range(i+1, fragmentNumbers):\n",
    "        pointI = i+10 # Center of the fragment\n",
    "        pointJ = j+10\n",
    "        if Bool[i,j]:\n",
    "          if A[pointI,pointJ] != 0 and A[pointI,pointJ] != 1 :\n",
    "            R[pointI,pointJ] = A[pointI,pointJ]\n",
    "          elif A[pointI,pointJ] == 0:\n",
    "            R[pointI,pointJ] = math.exp(-np.linalg.norm(data.iloc[pointI,:nbcol] - data.iloc[pointJ,:nbcol])**2)\n",
    "          R[pointJ,pointI] = R[pointI,pointJ]\n",
    "\n",
    "\n",
    "\n",
    "  data.drop(data.iloc[:, dim:nbcol], axis=1, inplace=True)\n",
    "  data.iloc[:,:dim] = spectral_embedding(A+R,dim)\n",
    "  del A\n",
    "  del R\n",
    "  return data\n",
    "\n",
    "\n",
    "\n",
    "def dimensionReduction(data, nbcol, dim=3):\n",
    "  group = data.groupby(\"Series\")\n",
    "  reducedData = group.apply(reduce, nbcol, dim)\n",
    "  return reducedData\n",
    "\n",
    "train2 = train\n",
    "test2 = test\n",
    "\n",
    "dim = 6\n",
    "\n",
    "start = timer()\n",
    "train_r = dimensionReduction(train, nb_col, dim)\n",
    "end = timer()\n",
    "time1 = end - start\n",
    "print(train_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quatre voisins\n",
    "\n",
    "def reduce(data, nbcol, dim=3, repetition=False):\n",
    "  # data is a dataframe representing a serie of the dataset\n",
    "  size = data.shape[0]\n",
    "    \n",
    "  # If the number or data points if less or equal to the reduced dimension wished, drop the series\n",
    "  if dim >= size:\n",
    "    data.drop(data.index, inplace=True)\n",
    "    return data\n",
    "  #if size > 25:\n",
    "  #  repetition = True\n",
    "    \n",
    "\n",
    "  A = np.zeros((size, size))\n",
    "  np.fill_diagonal(A, 1) \n",
    "  R = np.zeros((size, size)) # Repetition neighbourhood matrix\n",
    "  \n",
    "\n",
    "  # Handling the extreme data points\n",
    "  A[0,1] = math.exp(-np.linalg.norm(data.iloc[0,:nbcol] - data.iloc[1,:nbcol]))\n",
    "  A[1,0] = A[0,1]\n",
    "  end = size - 1 # Last index of A\n",
    "  bend = end - 1\n",
    "  A[end,bend] = math.exp(-np.linalg.norm(data.iloc[end,:nbcol] - data.iloc[bend,:nbcol]))\n",
    "  A[bend,end] = A[end,bend]\n",
    "\n",
    "  if repetition == True: # We compute simultaneously the adjacent temporal neighbourhood matrix and the repetition temporal neighbourhood matrix\n",
    "\n",
    "    endRepetition = end-10 # Last index of the data points while computing the repetition neighbourhoods\n",
    "    fragmentNumbers = endRepetition - 9 # Number of fragments\n",
    "    M = np.zeros((fragmentNumbers, fragmentNumbers)) # Similarity matrix of the fragments\n",
    "    fragments = list() # List containing the fragments. Each element of the list contains the coordinates (extracted dataframe) of the data points in the fragment\n",
    "    M_mod = np.zeros((fragmentNumbers, fragmentNumbers)) # Similarity matrix M after windowing\n",
    "\n",
    "    # Handling the intermediate data points for adjacent neighbours\n",
    "    for i in range(1,end):\n",
    "      A[i,i-1] =  math.exp(-np.linalg.norm(data.iloc[i,:nbcol] - data.iloc[i-1,:nbcol]))\n",
    "      A[i-1,i] = A[i,i-1]\n",
    "      A[i,i+1] = math.exp(-np.linalg.norm(data.iloc[i,:nbcol] - data.iloc[i+1,:nbcol]))\n",
    "      A[i+1,i] = A[i,i+1]\n",
    "      if i >= 10 and i <= endRepetition:\n",
    "        fragments.append(data.iloc[i-10:i+11, :nbcol])\n",
    "\n",
    "    # Computing the M matrix\n",
    "    for i in range(0,fragmentNumbers):\n",
    "      for j in range(0,i):\n",
    "        M[i,j] = dtw(fragments[i], fragments[j])\n",
    "        M[j,i] = M[i,j]\n",
    "\n",
    "    # Performing temporal windowing of M\n",
    "    for i in range(0,fragmentNumbers):\n",
    "      for j in range(i+1, fragmentNumbers):\n",
    "        for b in range(0, 20):\n",
    "          if i-b > 0 and j-b >0:  #  ET LES AUTRES ?\n",
    "            M_mod[i,j] = M_mod[i,j] + M[i-b,j-b]\n",
    "        M_mod[i,j] = M_mod[i,j] / 20\n",
    "        M_mod[j,i] = M_mod[i,j]\n",
    "        \n",
    "      \n",
    "\n",
    "    \n",
    "    # Searching for similar fragments, extracting the similar fragments and building the matrix R\n",
    "    b = 0.75\n",
    "    Bool = (M_mod < M_mod.mean(axis=1) - b * M_mod.std(axis=1))\n",
    "    for i in range(0, fragmentNumbers):\n",
    "      for j in range(i+1, fragmentNumbers):\n",
    "        pointI = i+10 # Center of the fragment\n",
    "        pointJ = j+10\n",
    "        if Bool[i,j]:\n",
    "          if A[pointI,pointJ] != 0 and A[pointI,pointJ] != 1 :\n",
    "            R[pointI,pointJ] = A[pointI,pointJ]\n",
    "          elif A[pointI,pointJ] == 0:\n",
    "            R[pointI,pointJ] = math.exp(-np.linalg.norm(data.iloc[pointI,:nbcol] - data.iloc[pointJ,:nbcol]))\n",
    "          R[pointJ,pointI] = R[pointI,pointJ]\n",
    "\n",
    "\n",
    "\n",
    "  else: # We compute only the adjacent temporal neighbourhood matrix\n",
    "    \n",
    "\n",
    "    # Handling the intermediate data points for adjacent neighbours\n",
    "    for i in range(2,end-1):\n",
    "      A[i,i-1] =  math.exp(-np.linalg.norm(data.iloc[i,:nbcol] - data.iloc[i-1,:nbcol]))\n",
    "      A[i-1,i] = A[i,i-1]\n",
    "      A[i,i-2] =  math.exp(-np.linalg.norm(data.iloc[i,:nbcol] - data.iloc[i-2,:nbcol]))\n",
    "      A[i-2,i] = A[i,i-2]\n",
    "      A[i,i+1] = math.exp(-np.linalg.norm(data.iloc[i,:nbcol] - data.iloc[i+1,:nbcol]))\n",
    "      A[i+1,i] = A[i,i+1]\n",
    "      A[i,i+2] =  math.exp(-np.linalg.norm(data.iloc[i,:nbcol] - data.iloc[i+2,:nbcol]))\n",
    "      A[i+2,i] = A[i,i+2]\n",
    "  \n",
    "  #to_drop = [\"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\"]\n",
    "  data.drop(data.iloc[:, dim:nbcol], axis=1, inplace=True)\n",
    "  #data.drop(columns=to_drop, inplace=True)\n",
    "  data.iloc[:,:dim] = spectral_embedding(A+R,dim)\n",
    "  return data\n",
    "\n",
    "\n",
    "\n",
    "def dimensionReduction(data, nbcol, dim=3):\n",
    "  #data = data.dropna()\n",
    "  group = data.groupby(\"Series\")\n",
    "  reducedData = group.apply(reduce, nbcol, dim)\n",
    "  return reducedData\n",
    "\n",
    "train2 = train\n",
    "test2 = test\n",
    "\n",
    "dim = 2\n",
    "\n",
    "start = timer()\n",
    "train_r = dimensionReduction(train, nb_col, dim)\n",
    "end = timer()\n",
    "time1 = end - start\n",
    "print(train_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1730,
     "status": "ok",
     "timestamp": 1594298971076,
     "user": {
      "displayName": "Véronne Yepmo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgqH82zY4SlxjzAyvHbBobvn-Nfd4c_b3i6F_ADfA=s64",
      "userId": "01798836279637929908"
     },
     "user_tz": -120
    },
    "id": "60JKS0P61Oi8",
    "outputId": "fef0bf13-c3fe-4b7b-995b-c5618bc42aff"
   },
   "outputs": [],
   "source": [
    "start = timer()\n",
    "test_r = dimensionReduction(test, nb_col, dim)\n",
    "end = timer()\n",
    "time2 = end - start\n",
    "train = train2\n",
    "test = test2\n",
    "print(test_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FFQLVuV-BLrx"
   },
   "source": [
    "## Corr coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 431
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 653288,
     "status": "ok",
     "timestamp": 1594299630307,
     "user": {
      "displayName": "Véronne Yepmo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgqH82zY4SlxjzAyvHbBobvn-Nfd4c_b3i6F_ADfA=s64",
      "userId": "01798836279637929908"
     },
     "user_tz": -120
    },
    "id": "SZI8HT2PBLrx",
    "outputId": "a0833f3f-b3f3-40a8-c64b-32f12be07642"
   },
   "outputs": [],
   "source": [
    "start = timer()\n",
    "\n",
    "\n",
    "nb_col = len(train_r.drop(['classe','Series'],axis=1).columns)\n",
    "nb_col\n",
    "\n",
    "# Calcul de la dérivée et de la somme cumulée\n",
    "deriv = train_r.groupby('Series').transform(lambda x: x.diff()).iloc[:,0:nb_col]\n",
    "\n",
    "cumsum = train_r.groupby('Series').transform(lambda x: x.cumsum()).iloc[:,0:nb_col]\n",
    "\n",
    "data = pd.concat([train_r.iloc[:,0:nb_col],deriv,cumsum],axis=1)\n",
    "data.columns = np.linspace(0,3*nb_col,3*nb_col,dtype=int)\n",
    "\n",
    "train_r = pd.concat([data,train_r[['classe','Series']]], axis=1)\n",
    "train_r.dropna(inplace=True)\n",
    "\n",
    "#print(train_r)\n",
    "\n",
    "deriv = test_r.groupby('Series').transform(lambda x: x.diff()).iloc[:,0:nb_col]\n",
    "\n",
    "cumsum = test_r.groupby('Series').transform(lambda x: x.cumsum()).iloc[:,0:nb_col]\n",
    "\n",
    "data = pd.concat([test_r.iloc[:,0:nb_col],deriv,cumsum],axis=1)\n",
    "data.columns = np.linspace(0,3*nb_col,3*nb_col,dtype=int)\n",
    "\n",
    "test_r = pd.concat([test_r.iloc[:,0:nb_col],deriv,cumsum,test_r[['classe','Series']]],\n",
    "          axis=1)\n",
    "test_r.dropna(inplace=True)\n",
    "\n",
    "#print(test_r)\n",
    "\n",
    "\n",
    "####### M-histogramme #########\n",
    "\n",
    "# Paramètres\n",
    "max_comb = comb(nb_col,2)*3*2\n",
    "\n",
    "\n",
    "print(\"Nombre de M-histogrammes : \",max_comb)\n",
    "\n",
    "eval_int = 0\n",
    "# Apprentissage vue\n",
    "for app in range(0,4):\n",
    "    print(\"*****************************\")\n",
    "    print(\"Apprentissage: \",app)\n",
    "    print(\"*****************************\")\n",
    "    train_nngrams = list() #Liste des M-Histogrammes de l'ensemble d'apprentissage pour chaque vue\n",
    "    test_nngrams = list() #Liste des M-Histogrammes de l'ensemble de test\n",
    "    learners = list()\n",
    "    combin=list()           #Liste des combinaisons dim1+dim2+TypeHistogramme\n",
    "    \n",
    "    # Apprentissage M-histogramme\n",
    "    i=0\n",
    "    while i<max_comb :\n",
    "        #if i%5==0:\n",
    "            #print(\"*****************************\")\n",
    "            #print(\"TOUR : \",i)\n",
    "            #print(\"*****************************\")\n",
    "        # Choosing : Dimensional features ||  Simple, Deriv or Cumsum ||  Bigrams or 1grams \n",
    "        dim1rand = np.random.randint(0,nb_col)\n",
    "        dim2rand = np.random.randint(0,nb_col)\n",
    "        while dim2rand == dim1rand :\n",
    "            dim2rand = np.random.randint(0,nb_col)\n",
    "\n",
    "\n",
    "        transform = np.random.randint(0,3)\n",
    "        dim1 = dim1rand+transform*nb_col\n",
    "        dim2 = dim2rand+transform*nb_col\n",
    "\n",
    "        nngrams = np.random.randint(0,2)    \n",
    "\n",
    "        #print(\"Dim1 : \",dim1,\"   Dim2 : \",dim2,\"    NNGrams: \",nngrams)\n",
    "\n",
    "        if [dim1,dim2,nngrams] in combin or [dim2,dim1,nngrams] in combin : \n",
    "            continue\n",
    "        else :\n",
    "            combin.append([dim1,dim2,nngrams]) \n",
    "            i+=1\n",
    "\n",
    "        if nngrams == 0:\n",
    "\n",
    "            ub1,ub2 = bigramsTransform(train_r.copy(),dim1,dim2)\n",
    "\n",
    "            train_group = train_r.groupby('Series')        \n",
    "            htr = train_group.apply(lambda x : np.ndarray.tolist(np.ndarray.flatten(\n",
    "                        np.histogram2d(x.iloc[:,dim1].values,x.iloc[:,dim2].values,bins=[ub1,ub2],density=True)[0])))\n",
    "            htr = pd.DataFrame(htr.values.tolist())\n",
    "            train_nngrams.append(htr)\n",
    "\n",
    "\n",
    "            test_group = test_r.groupby('Series')\n",
    "            htt = test_group.apply(lambda x : np.ndarray.tolist(np.ndarray.flatten(\n",
    "                        np.histogram2d(x.iloc[:,dim1].values,x.iloc[:,dim2].values,bins=[ub1,ub2],density=True)[0])))\n",
    "            htt = pd.DataFrame(htt.values.tolist())\n",
    "            test_nngrams.append(htt)\n",
    "\n",
    "            learners.append(('clf',KNeighborsClassifier(1)))\n",
    "\n",
    "\n",
    "        else :\n",
    "\n",
    "            ub1h,ub2h = onegramsTransform(train_r.copy(),dim1,dim2) \n",
    "\n",
    "            train_group = train_r.groupby('Series')\n",
    "            h1htr = train_group.apply(lambda x : np.ndarray.tolist(np.ndarray.flatten(\n",
    "                        np.histogram(x.iloc[:,dim1].values,bins=ub1h,density=True)[0])))\n",
    "            h1htr = pd.DataFrame(h1htr.values.tolist())\n",
    "            train_nngrams.append(h1htr)\n",
    "\n",
    "            h2htr = train_group.apply(lambda x : np.ndarray.tolist(np.ndarray.flatten(\n",
    "                        np.histogram(x.iloc[:,dim2].values,bins=ub2h,density=True)[0])))\n",
    "            h2htr = pd.DataFrame(h2htr.values.tolist())\n",
    "            train_nngrams.append(h2htr)\n",
    "\n",
    "\n",
    "            test_group = test_r.groupby('Series')\n",
    "            h1htt = test_group.apply(lambda x : np.ndarray.tolist(np.ndarray.flatten(\n",
    "                        np.histogram(x.iloc[:,dim1].values,bins=ub1h,density=True)[0])))\n",
    "            h1htt = pd.DataFrame(h1htt.values.tolist())\n",
    "            test_nngrams.append(h1htt)\n",
    "\n",
    "            h2htt = test_group.apply(lambda x : np.ndarray.tolist(np.ndarray.flatten(\n",
    "                        np.histogram(x.iloc[:,dim2].values,bins=ub2h,density=True)[0])))\n",
    "            h2htt = pd.DataFrame(h2htt.values.tolist())\n",
    "            test_nngrams.append(h2htt)\n",
    "\n",
    "            learners.append(('clf',KNeighborsClassifier(1)))\n",
    "            learners.append(('clf',KNeighborsClassifier(1)))\n",
    "\n",
    "    # Score en validation\n",
    "    cl = train_group['classe'].apply(lambda x : x.iloc[0]).reset_index(drop=True) #Liste des classes pour chaque série, en ordre\n",
    "    se = np.arange(len(train_nngrams[0]))\n",
    "    #train_index : index des séries de l'ensemble d'apprentissage, y_train: classes des séries de l'ensemble d'apprentissage, indexées par les index des séries\n",
    "    train_index, test_index, y_train, y_test = train_test_split(se, cl,stratify=cl,test_size=0.2) \n",
    "\n",
    "    x_train = list()\n",
    "    x_test = list()\n",
    "    for j in range(len(train_nngrams)): #Chaque item de x_train contiendra pour une vue la liste des histogrammes des séries d'entraînement\n",
    "        x_train.append(train_nngrams[j].iloc[train_index,:].reset_index(drop=True))  \n",
    "    for j in range(len(train_nngrams)):\n",
    "        x_test.append(train_nngrams[j].iloc[test_index,:].reset_index(drop=True))\n",
    "\n",
    "    fitted_estimators, label_encoder = el.fit_multiple_estimators(learners, x_train, y_train.reset_index(drop=True))\n",
    "    y_pred = el.predict_from_multiple_estimator(fitted_estimators, label_encoder, x_test)\n",
    "    score_val = np.round(accuracy_score(y_pred, y_test.reset_index(drop=True)),4)\n",
    "    print(\"SCORE Training VUE N°\",app,\" : \",score_val )\n",
    "    \n",
    "    # Score en test\n",
    "    train_group = train_r.groupby('Series')\n",
    "    train_classe = train_group['classe'].apply(lambda x : x.iloc[0]).reset_index(drop=True)\n",
    "\n",
    "    test_group = test_r.groupby('Series')\n",
    "    test_classe = test_group['classe'].apply(lambda x : x.iloc[0]).reset_index(drop=True)\n",
    "\n",
    "    fitted_estimators, label_encoder = el.fit_multiple_estimators(learners, train_nngrams, train_classe)\n",
    "    y_pred = el.predict_from_multiple_estimator(fitted_estimators, label_encoder, test_nngrams)\n",
    "    \n",
    "    score_test = np.round(accuracy_score(y_pred, test_classe),4)\n",
    "    print(\"SCORE TEST: \", score_test)\n",
    "  \n",
    "    \n",
    "    if eval_int < score_val :\n",
    "        eval_int=score_val\n",
    "        eval_fi=score_test\n",
    "        \n",
    "print(\"SCORE FINAL: \", eval_fi)\n",
    "\n",
    "end = timer()\n",
    "time3 = end - start\n",
    "timeF = time1 + time2 + time3\n",
    "print(\"TOTAL TIME :\", timeF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [
    "8HgXCZpPBLrY"
   ],
   "name": "bigram_ecml_cap.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
